{
  "智能文件分析": {
    "description": "智能文件分析工具，支持图片内容识别、文档内容分析、AI深度理解",
    "code": "import os\nimport json\nimport base64\nimport mimetypes\nimport hashlib\nimport datetime\nfrom pathlib import Path\nfrom typing import Dict, List, Any, Optional\n\ntry:\n    from PIL import Image\n    PIL_AVAILABLE = True\nexcept ImportError:\n    PIL_AVAILABLE = False\n\ntry:\n    import fitz  # PyMuPDF\n    PDF_AVAILABLE = True\nexcept ImportError:\n    PDF_AVAILABLE = False\n\ntry:\n    import pandas as pd\n    PANDAS_AVAILABLE = True\nexcept ImportError:\n    PANDAS_AVAILABLE = False\n\ntry:\n    import pytesseract\n    from PIL import ImageEnhance\n    # 设置Tesseract路径\n    pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'\n    OCR_AVAILABLE = True\nexcept ImportError:\n    OCR_AVAILABLE = False\n\ndef analyze_file_content(file_path):\n    \"\"\"深度分析文件内容，包括AI理解和内容提取\"\"\"\n    try:\n        if not os.path.exists(file_path):\n            return f\"文件不存在: {file_path}\"\n        \n        file_path = Path(file_path)\n        \n        # 获取基本信息\n        basic_info = get_basic_file_info(file_path)\n        \n        # 根据文件类型进行内容分析\n        if is_image_file(file_path):\n            content_analysis = analyze_image_content(file_path)\n        elif is_document_file(file_path):\n            content_analysis = analyze_document_content(file_path)\n        else:\n            content_analysis = {\"type\": \"unknown\", \"message\": \"暂不支持此文件类型的内容分析\"}\n        \n        # 合并分析结果\n        result = {\n            \"basic_info\": basic_info,\n            \"content_analysis\": content_analysis,\n            \"analysis_time\": datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n        }\n        \n        return json.dumps(result, ensure_ascii=False, indent=2)\n        \n    except Exception as e:\n        return f\"文件内容分析失败: {str(e)}\"\n\ndef analyze_image_content(file_path):\n    \"\"\"分析图片内容，包括场景识别、物体检测、文字提取等\"\"\"\n    if not PIL_AVAILABLE:\n        return {\n            \"type\": \"image\",\n            \"error\": \"PIL库未安装，无法分析图片内容\",\n            \"suggestion\": \"请安装Pillow库: pip install Pillow\"\n        }\n    \n    try:\n        with Image.open(file_path) as img:\n            # 基础图片信息\n            basic_info = {\n                \"type\": \"image\",\n                \"format\": img.format,\n                \"mode\": img.mode,\n                \"width\": img.width,\n                \"height\": img.height,\n                \"aspect_ratio\": round(img.width / img.height, 2),\n                \"color_depth\": get_color_depth(img.mode)\n            }\n            \n            # 图片内容分析\n            content_analysis = {\n                \"scene_description\": analyze_image_scene(img),\n                \"object_detection\": detect_objects_in_image(img),\n                \"text_extraction\": extract_text_from_image(img),\n                \"ocr_text\": perform_ocr_on_image(img),\n                \"color_analysis\": analyze_image_colors(img),\n                \"composition_analysis\": analyze_image_composition(img)\n            }\n            \n            # 合并结果\n            result = {**basic_info, **content_analysis}\n            return result\n            \n    except Exception as e:\n        return {\n            \"type\": \"image\",\n            \"error\": f\"图片内容分析失败: {str(e)}\"\n        }\n\ndef perform_ocr_on_image(img):\n    \"\"\"对图片进行OCR文字识别\"\"\"\n    if not OCR_AVAILABLE:\n        return {\n            \"status\": \"error\",\n            \"message\": \"OCR功能未安装，请安装pytesseract库: pip install pytesseract\",\n            \"suggestion\": \"同时需要安装Tesseract OCR引擎\"\n        }\n    \n    try:\n        # 预处理图片以提高OCR准确性\n        img_processed = preprocess_image_for_ocr(img)\n        \n        # 尝试多种OCR配置\n        ocr_results = []\n        \n        # 配置1：默认配置\n        try:\n            text_default = pytesseract.image_to_string(img_processed, lang='chi_sim+eng')\n            if text_default.strip():\n                ocr_results.append({\n                    \"config\": \"默认配置\",\n                    \"text\": text_default.strip(),\n                    \"confidence\": \"标准\"\n                })\n        except Exception as e:\n            pass\n        \n        # 配置2：只识别中文\n        try:\n            text_chinese = pytesseract.image_to_string(img_processed, lang='chi_sim')\n            if text_chinese.strip():\n                ocr_results.append({\n                    \"config\": \"中文识别\",\n                    \"text\": text_chinese.strip(),\n                    \"confidence\": \"标准\"\n                })\n        except Exception as e:\n            pass\n        \n        # 配置3：只识别英文\n        try:\n            text_english = pytesseract.image_to_string(img_processed, lang='eng')\n            if text_english.strip():\n                ocr_results.append({\n                    \"config\": \"英文识别\",\n                    \"text\": text_english.strip(),\n                    \"confidence\": \"标准\"\n                })\n        except Exception as e:\n            pass\n        \n        # 配置4：数字识别\n        try:\n            text_digits = pytesseract.image_to_string(img_processed, lang='eng', config='--psm 6 -c tessedit_char_whitelist=0123456789')\n            if text_digits.strip():\n                ocr_results.append({\n                    \"config\": \"数字识别\",\n                    \"text\": text_digits.strip(),\n                    \"confidence\": \"标准\"\n                })\n        except Exception as e:\n            pass\n        \n        if ocr_results:\n            # 选择最佳结果（通常是最长的文本）\n            best_result = max(ocr_results, key=lambda x: len(x[\"text\"]))\n            \n            return {\n                \"status\": \"success\",\n                \"extracted_text\": best_result[\"text\"],\n                \"all_results\": ocr_results,\n                \"text_length\": len(best_result[\"text\"]),\n                \"word_count\": len(best_result[\"text\"].split()),\n                \"has_text\": True,\n                \"description\": f\"成功识别到{len(best_result['text'])}个字符的文字内容\"\n            }\n        else:\n            return {\n                \"status\": \"no_text\",\n                \"extracted_text\": \"\",\n                \"all_results\": [],\n                \"text_length\": 0,\n                \"word_count\": 0,\n                \"has_text\": False,\n                \"description\": \"未识别到任何文字内容\"\n            }\n        \n    except Exception as e:\n        return {\n            \"status\": \"error\",\n            \"message\": f\"OCR识别失败: {str(e)}\",\n            \"extracted_text\": \"\",\n            \"all_results\": [],\n            \"text_length\": 0,\n            \"word_count\": 0,\n            \"has_text\": False\n        }\n\ndef preprocess_image_for_ocr(img):\n    \"\"\"预处理图片以提高OCR准确性\"\"\"\n    try:\n        # 转换为RGB模式\n        if img.mode != 'RGB':\n            img = img.convert('RGB')\n        \n        # 转换为灰度图\n        img_gray = img.convert('L')\n        \n        # 增强对比度\n        enhancer = ImageEnhance.Contrast(img_gray)\n        img_enhanced = enhancer.enhance(2.0)\n        \n        # 增强锐度\n        sharpness_enhancer = ImageEnhance.Sharpness(img_enhanced)\n        img_sharp = sharpness_enhancer.enhance(1.5)\n        \n        return img_sharp\n        \n    except Exception as e:\n        # 如果预处理失败，返回原图\n        return img\n\ndef analyze_document_content(file_path):\n    \"\"\"分析文档内容，包括文本提取、主题分析、关键信息提取等\"\"\"\n    extension = file_path.suffix.lower()\n    \n    if extension == '.pdf':\n        return analyze_pdf_content(file_path)\n    elif extension == '.txt':\n        return analyze_text_content(file_path)\n    elif extension == '.csv':\n        return analyze_csv_content(file_path)\n    elif extension == '.json':\n        return analyze_json_content(file_path)\n    else:\n        return {\n            \"type\": \"document\",\n            \"message\": f\"暂不支持分析 {extension} 格式的文档内容\"\n        }\n\ndef analyze_image_scene(img):\n    \"\"\"分析图片场景\"\"\"\n    img_array = img.convert('L')\n    pixels = list(img_array.getdata())\n    avg_brightness = sum(pixels) / len(pixels)\n    \n    if avg_brightness > 200:\n        scene_type = \"明亮场景\"\n    elif avg_brightness > 100:\n        scene_type = \"正常亮度\"\n    else:\n        scene_type = \"暗光场景\"\n    \n    return {\n        \"scene_type\": scene_type,\n        \"brightness_level\": round(avg_brightness, 2),\n        \"description\": f\"这是一张{scene_type}的图片，平均亮度为{round(avg_brightness, 2)}\"\n    }\n\ndef detect_objects_in_image(img):\n    \"\"\"检测图片中的物体\"\"\"\n    img_array = img.convert('RGB')\n    pixels = list(img_array.getdata())\n    unique_colors = len(set(pixels))\n    \n    if unique_colors > 10000:\n        complexity = \"复杂\"\n        object_count_estimate = \"可能包含多个物体\"\n    elif unique_colors > 5000:\n        complexity = \"中等\"\n        object_count_estimate = \"可能包含几个主要物体\"\n    else:\n        complexity = \"简单\"\n        object_count_estimate = \"可能包含少量物体\"\n    \n    return {\n        \"complexity\": complexity,\n        \"unique_colors\": unique_colors,\n        \"object_count_estimate\": object_count_estimate,\n        \"description\": f\"图片复杂度为{complexity}，包含{unique_colors}种不同颜色\"\n    }\n\ndef extract_text_from_image(img):\n    \"\"\"从图片中提取文字\"\"\"\n    img_array = img.convert('L')\n    pixels = list(img_array.getdata())\n    width, height = img.size\n    \n    # 改进的边缘密度计算\n    edge_density = calculate_edge_density_improved(pixels, width, height)\n    \n    # 计算文字特征\n    text_features = analyze_text_features(img)\n    \n    # 综合判断文字可能性\n    if edge_density > 0.25 or text_features['high_contrast_areas'] > 0.1:\n        text_likelihood = \"高\"\n        description = \"图片很可能包含文字内容\"\n    elif edge_density > 0.15 or text_features['high_contrast_areas'] > 0.05:\n        text_likelihood = \"中等\"\n        description = \"图片可能包含少量文字\"\n    else:\n        text_likelihood = \"低\"\n        description = \"图片可能不包含文字\"\n    \n    return {\n        \"text_likelihood\": text_likelihood,\n        \"edge_density\": round(edge_density, 3),\n        \"text_features\": text_features,\n        \"description\": description\n    }\n\ndef calculate_edge_density_improved(pixels, width, height):\n    \"\"\"改进的边缘密度计算\"\"\"\n    edge_count = 0\n    total_pixels = len(pixels)\n    \n    # 水平边缘检测\n    for y in range(height):\n        for x in range(1, width):\n            idx = y * width + x\n            if abs(pixels[idx] - pixels[idx - 1]) > 25:\n                edge_count += 1\n    \n    # 垂直边缘检测\n    for y in range(1, height):\n        for x in range(width):\n            idx = y * width + x\n            if abs(pixels[idx] - pixels[idx - width]) > 25:\n                edge_count += 1\n    \n    return edge_count / (total_pixels * 2) if total_pixels > 0 else 0\n\ndef analyze_text_features(img):\n    \"\"\"分析文字特征\"\"\"\n    img_array = img.convert('L')\n    pixels = list(img_array.getdata())\n    width, height = img.size\n    \n    # 计算高对比度区域\n    high_contrast_pixels = 0\n    total_pixels = len(pixels)\n    \n    for i in range(1, len(pixels)):\n        if abs(pixels[i] - pixels[i-1]) > 50:\n            high_contrast_pixels += 1\n    \n    high_contrast_ratio = high_contrast_pixels / total_pixels if total_pixels > 0 else 0\n    \n    # 计算亮度分布\n    brightness_values = [p for p in pixels]\n    avg_brightness = sum(brightness_values) / len(brightness_values) if brightness_values else 0\n    \n    # 计算标准差（用于判断对比度）\n    variance = sum((p - avg_brightness) ** 2 for p in brightness_values) / len(brightness_values) if brightness_values else 0\n    std_dev = variance ** 0.5\n    \n    return {\n        \"high_contrast_areas\": round(high_contrast_ratio, 3),\n        \"average_brightness\": round(avg_brightness, 2),\n        \"contrast_std_dev\": round(std_dev, 2),\n        \"description\": f\"高对比度区域占比{round(high_contrast_ratio * 100, 1)}%，平均亮度{round(avg_brightness, 1)}，对比度标准差{round(std_dev, 1)}\"\n    }\n\ndef analyze_image_colors(img):\n    \"\"\"分析图片颜色特征\"\"\"\n    img_array = img.convert('RGB')\n    pixels = list(img_array.getdata())\n    color_counts = {}\n    for pixel in pixels:\n        color_counts[pixel] = color_counts.get(pixel, 0) + 1\n    \n    sorted_colors = sorted(color_counts.items(), key=lambda x: x[1], reverse=True)\n    dominant_colors = sorted_colors[:5]\n    \n    total_pixels = len(pixels)\n    color_analysis = []\n    \n    for color, count in dominant_colors:\n        percentage = (count / total_pixels) * 100\n        color_analysis.append({\n            \"color\": f\"RGB{color}\",\n            \"percentage\": round(percentage, 2),\n            \"count\": count\n        })\n    \n    return {\n        \"dominant_colors\": color_analysis,\n        \"total_unique_colors\": len(color_counts),\n        \"description\": f\"图片包含{len(color_counts)}种不同颜色，主要颜色占比最高为{color_analysis[0]['percentage']}%\"\n    }\n\ndef analyze_image_composition(img):\n    \"\"\"分析图片构图\"\"\"\n    width, height = img.size\n    aspect_ratio = width / height\n    \n    if abs(aspect_ratio - 1) < 0.1:\n        composition = \"正方形构图\"\n    elif aspect_ratio > 1.5:\n        composition = \"横向构图\"\n    elif aspect_ratio < 0.7:\n        composition = \"纵向构图\"\n    else:\n        composition = \"标准构图\"\n    \n    if width * height > 8000000:\n        resolution_quality = \"高分辨率\"\n    elif width * height > 2000000:\n        resolution_quality = \"中等分辨率\"\n    else:\n        resolution_quality = \"低分辨率\"\n    \n    return {\n        \"composition_type\": composition,\n        \"resolution_quality\": resolution_quality,\n        \"pixel_count\": width * height,\n        \"description\": f\"{composition}，{resolution_quality}，总像素{width * height:,}\"\n    }\n\ndef analyze_pdf_content(file_path):\n    \"\"\"分析PDF文档内容\"\"\"\n    if not PDF_AVAILABLE:\n        return {\n            \"type\": \"pdf\",\n            \"error\": \"PyMuPDF库未安装，无法分析PDF内容\",\n            \"suggestion\": \"请安装PyMuPDF库: pip install PyMuPDF\"\n        }\n    \n    try:\n        doc = fitz.open(file_path)\n        full_text = \"\"\n        for page_num in range(len(doc)):\n            page = doc.load_page(page_num)\n            full_text += page.get_text()\n        \n        text_analysis = analyze_text_content_from_string(full_text)\n        \n        result = {\n            \"type\": \"pdf\",\n            \"page_count\": len(doc),\n            \"title\": doc.metadata.get(\"title\", \"未知\"),\n            \"author\": doc.metadata.get(\"author\", \"未知\"),\n            \"subject\": doc.metadata.get(\"subject\", \"未知\"),\n            \"text_analysis\": text_analysis\n        }\n        \n        doc.close()\n        return result\n        \n    except Exception as e:\n        return {\n            \"type\": \"pdf\",\n            \"error\": f\"PDF内容分析失败: {str(e)}\"\n        }\n\ndef analyze_text_content(file_path):\n    \"\"\"分析文本文件内容\"\"\"\n    try:\n        with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:\n            content = f.read()\n        \n        return analyze_text_content_from_string(content)\n        \n    except Exception as e:\n        return {\n            \"type\": \"text\",\n            \"error\": f\"文本内容分析失败: {str(e)}\"\n        }\n\ndef analyze_text_content_from_string(text):\n    \"\"\"分析文本字符串内容\"\"\"\n    if not text.strip():\n        return {\n            \"type\": \"text\",\n            \"message\": \"文件为空或只包含空白字符\"\n        }\n    \n    lines = text.split('\\n')\n    words = text.split()\n    sentences = text.split('。')\n    avg_sentence_length = len(words) / len(sentences) if sentences else 0\n    \n    if len(text) < 100:\n        text_type = \"短文本\"\n    elif len(text) < 1000:\n        text_type = \"中等文本\"\n    else:\n        text_type = \"长文本\"\n    \n    chinese_chars = sum(1 for char in text if '\\u4e00' <= char <= '\\u9fff')\n    english_chars = sum(1 for char in text if char.isalpha() and ord(char) < 128)\n    \n    if chinese_chars > english_chars:\n        language = \"中文\"\n    elif english_chars > chinese_chars:\n        language = \"英文\"\n    else:\n        language = \"混合语言\"\n    \n    word_freq = {}\n    for word in words:\n        if len(word) > 1:\n            word_freq[word] = word_freq.get(word, 0) + 1\n    \n    sorted_words = sorted(word_freq.items(), key=lambda x: x[1], reverse=True)\n    keywords = [word for word, count in sorted_words[:10] if count > 1]\n    \n    return {\n        \"type\": \"text\",\n        \"character_count\": len(text),\n        \"line_count\": len(lines),\n        \"word_count\": len(words),\n        \"sentence_count\": len(sentences),\n        \"avg_sentence_length\": round(avg_sentence_length, 2),\n        \"text_type\": text_type,\n        \"language\": language,\n        \"keywords\": keywords,\n        \"content_preview\": text[:500] + \"...\" if len(text) > 500 else text,\n        \"description\": f\"{text_type}，{language}，包含{len(words)}个词，{len(sentences)}个句子\"\n    }\n\ndef analyze_csv_content(file_path):\n    \"\"\"分析CSV文件内容\"\"\"\n    if not PANDAS_AVAILABLE:\n        return {\n            \"type\": \"csv\",\n            \"error\": \"pandas库未安装，无法分析CSV内容\",\n            \"suggestion\": \"请安装pandas库: pip install pandas\"\n        }\n    \n    try:\n        df = pd.read_csv(file_path)\n        \n        basic_info = {\n            \"type\": \"csv\",\n            \"row_count\": len(df),\n            \"column_count\": len(df.columns),\n            \"columns\": df.columns.tolist()\n        }\n        \n        data_types = df.dtypes.to_dict()\n        numeric_columns = df.select_dtypes(include=['number']).columns.tolist()\n        text_columns = df.select_dtypes(include=['object']).columns.tolist()\n        \n        numeric_stats = {}\n        for col in numeric_columns:\n            numeric_stats[col] = {\n                \"mean\": float(df[col].mean()) if not df[col].isna().all() else None,\n                \"std\": float(df[col].mean()) if not df[col].isna().all() else None,\n                \"min\": float(df[col].min()) if not df[col].isna().all() else None,\n                \"max\": float(df[col].max()) if not df[col].isna().all() else None\n            }\n        \n        missing_values = df.isnull().sum().to_dict()\n        preview = df.head(5).to_dict()\n        \n        result = {\n            **basic_info,\n            \"data_types\": data_types,\n            \"numeric_columns\": numeric_columns,\n            \"text_columns\": text_columns,\n            \"numeric_stats\": numeric_stats,\n            \"missing_values\": missing_values,\n            \"preview\": preview,\n            \"description\": f\"CSV文件包含{len(df)}行{len(df.columns)}列数据，其中{len(numeric_columns)}个数值列，{len(text_columns)}个文本列\"\n        }\n        \n        return result\n        \n    except Exception as e:\n        return {\n            \"type\": \"csv\",\n            \"error\": f\"CSV内容分析失败: {str(e)}\"\n        }\n\ndef analyze_json_content(file_path):\n    \"\"\"分析JSON文件内容\"\"\"\n    try:\n        with open(file_path, 'r', encoding='utf-8') as f:\n            data = json.load(f)\n        \n        basic_info = {\n            \"type\": \"json\",\n            \"data_type\": type(data).__name__\n        }\n        \n        structure_analysis = analyze_json_structure(data)\n        content_preview = json.dumps(data, ensure_ascii=False, indent=2)[:500] + \"...\" if len(json.dumps(data)) > 500 else json.dumps(data, ensure_ascii=False, indent=2)\n        \n        result = {\n            **basic_info,\n            \"structure_analysis\": structure_analysis,\n            \"content_preview\": content_preview,\n            \"description\": f\"JSON文件包含{structure_analysis.get('total_elements', 0)}个元素，数据结构为{type(data).__name__}\"\n        }\n        \n        return result\n        \n    except Exception as e:\n        return {\n            \"type\": \"json\",\n            \"error\": f\"JSON内容分析失败: {str(e)}\"\n        }\n\ndef get_basic_file_info(file_path):\n    \"\"\"获取文件基本信息\"\"\"\n    stat = file_path.stat()\n    file_hash = calculate_file_hash(file_path)\n    mime_type, _ = mimetypes.guess_type(str(file_path))\n    \n    return {\n        \"file_name\": file_path.name,\n        \"file_path\": str(file_path.absolute()),\n        \"file_size\": stat.st_size,\n        \"file_size_human\": format_file_size(stat.st_size),\n        \"file_extension\": file_path.suffix.lower(),\n        \"mime_type\": mime_type or \"unknown\",\n        \"created_time\": datetime.datetime.fromtimestamp(stat.st_ctime).strftime(\"%Y-%m-%d %H:%M:%S\"),\n        \"modified_time\": datetime.datetime.fromtimestamp(stat.st_mtime).strftime(\"%Y-%m-%d %H:%M:%S\"),\n        \"file_hash\": file_hash,\n        \"is_readable\": os.access(file_path, os.R_OK),\n        \"is_writable\": os.access(file_path, os.W_OK)\n    }\n\ndef is_image_file(file_path):\n    \"\"\"判断是否为图片文件\"\"\"\n    supported_formats = {'.jpg', '.jpeg', '.png', '.gif', '.bmp', '.tiff', '.webp'}\n    return file_path.suffix.lower() in supported_formats\n\ndef is_document_file(file_path):\n    \"\"\"判断是否为文档文件\"\"\"\n    supported_formats = {'.pdf', '.txt', '.doc', '.docx', '.csv', '.json', '.xml'}\n    return file_path.suffix.lower() in supported_formats\n\ndef calculate_file_hash(file_path):\n    \"\"\"计算文件哈希值\"\"\"\n    try:\n        hash_md5 = hashlib.md5()\n        with open(file_path, \"rb\") as f:\n            for chunk in iter(lambda: f.read(4096), b\"\"):\n                hash_md5.update(chunk)\n        return hash_md5.hexdigest()\n    except:\n        return \"计算失败\"\n\ndef format_file_size(size_bytes):\n    \"\"\"格式化文件大小\"\"\"\n    if size_bytes == 0:\n        return \"0B\"\n    \n    size_names = [\"B\", \"KB\", \"MB\", \"GB\", \"TB\"]\n    i = 0\n    while size_bytes >= 1024 and i < len(size_names) - 1:\n        size_bytes /= 1024.0\n        i += 1\n    \n    return f\"{size_bytes:.2f} {size_names[i]}\"\n\ndef get_color_depth(mode):\n    \"\"\"获取颜色深度\"\"\"\n    depth_map = {\n        \"1\": \"1位（黑白）\",\n        \"L\": \"8位（灰度）\",\n        \"P\": \"8位（调色板）\",\n        \"RGB\": \"24位（RGB）\",\n        \"RGBA\": \"32位（RGBA）\",\n        \"CMYK\": \"32位（CMYK）\",\n        \"YCbCr\": \"24位（YCbCr）\",\n        \"LAB\": \"24位（LAB）\",\n        \"HSV\": \"24位（HSV）\"\n    }\n    return depth_map.get(mode, f\"未知模式: {mode}\")\n\ndef calculate_edge_density(pixels, width, height):\n    \"\"\"计算边缘密度（用于判断是否包含文字）\"\"\"\n    edge_count = 0\n    total_pixels = len(pixels)\n    \n    for i in range(1, len(pixels)):\n        if abs(pixels[i] - pixels[i-1]) > 30:\n            edge_count += 1\n    \n    return edge_count / total_pixels if total_pixels > 0 else 0\n\ndef analyze_json_structure(data, max_depth=3):\n    \"\"\"分析JSON结构\"\"\"\n    def analyze_recursive(obj, depth=0):\n        if depth > max_depth:\n            return \"深度限制\"\n        \n        if isinstance(obj, dict):\n            return {\n                \"type\": \"object\",\n                \"keys\": list(obj.keys()),\n                \"key_count\": len(obj),\n                \"sample_values\": {k: analyze_recursive(v, depth + 1) for k, v in list(obj.items())[:3]}\n            }\n        elif isinstance(obj, list):\n            return {\n                \"type\": \"array\",\n                \"length\": len(obj),\n                \"sample_items\": [analyze_recursive(item, depth + 1) for item in obj[:3]]\n            }\n        else:\n            return {\n                \"type\": type(obj).__name__,\n                \"value\": str(obj)[:100] if obj else None\n            }\n    \n    structure = analyze_recursive(data)\n    \n    def count_elements(obj):\n        if isinstance(obj, (dict, list)):\n            return 1 + sum(count_elements(item) for item in (obj.values() if isinstance(obj, dict) else obj))\n        return 1\n    \n    structure[\"total_elements\"] = count_elements(data)\n    return structure\n\ndef upload_and_analyze_file(file_path):\n    \"\"\"上传并深度分析文件\"\"\"\n    try:\n        if not os.path.exists(file_path):\n            return f\"文件不存在: {file_path}\"\n        \n        analysis_result = analyze_file_content(file_path)\n        \n        result = f\"🔍 智能文件分析结果\\n\"\n        result += f\"━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\n\"\n        result += f\"文件路径: {file_path}\\n\"\n        result += f\"分析时间: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\"\n        result += f\"━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\n\"\n        result += analysis_result\n        \n        return result\n        \n    except Exception as e:\n        return f\"文件上传分析失败: {str(e)}\"",
    "type": "custom"
  }
}